import numpy as np
import os
import gymnasium as gym
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from gymnasium.envs.classic_control import utils
from typing import Optional
import importlib
import sys
import matplotlib.pyplot as plt
from collections import deque
import time

##Set the basic parameters
balance_time = 20  # å¹³è¡¡ä»»åŠ¡çš„æ€»æ—¶é•¿(ç§’)
h_in = 1/100       # æ—¶é—´æ­¥é•¿(0.01ç§’ï¼Œå³æ¯ç§’100æ­¥)
## balance_time: å®šä¹‰æ¸¸æˆæŒç»­çš„æ€»æ—¶é—´
## h_in: æ§åˆ¶ç®—æ³•çš„æ—¶é—´æ­¥é•¿ï¼Œè¡¨ç¤ºæ¨¡æ‹Ÿç²¾åº¦

# å®šä¹‰å¹³è¡¡åˆ¤æ–­å‡½æ•°ï¼ˆä»å¯è§†åŒ–ä»£ç ä¸­æå–ï¼‰
def check_balance_status_fixed(x, theta, x_dot, theta_dot):
    """ä¿®æ­£åçš„å¹³è¡¡çŠ¶æ€åˆ¤æ–­å‡½æ•°"""
    if x >= -0.1 and x <= 0.1 and theta > -0.1 and theta < 0.1 and x_dot >= -0.1 and x_dot <= 0.1 and theta_dot >= -0.1 and theta_dot <= 0.1:
        quality = 100
        status = "Perfect"
        is_balanced = True
    else:
        quality = 0
        status = "Lost"
        is_balanced = False
    return quality, status, is_balanced


def create_dynamic_reset_method(new_low, new_high):
    """
    åˆ›å»ºæ–°çš„resetæ–¹æ³•ï¼Œä½¿ç”¨æŒ‡å®šçš„èŒƒå›´
    """
    print(f"ğŸ”§ åˆ›å»ºåŠ¨æ€resetæ–¹æ³•ï¼ŒèŒƒå›´: [{new_low}, {new_high}]")
    
    def reset(
        self,
        *,
        seed: Optional[int] = None,
        options: Optional[dict] = None,
    ):
        # è°ƒç”¨çˆ¶ç±»çš„resetï¼ˆä½†ä¸ä¼ seedï¼Œé¿å…é‡å¤è®¾ç½®ï¼‰
        super(type(self), self).reset(seed=seed)
        
        # ğŸ”§ ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„èŒƒå›´ï¼Œä¸ä¾èµ–utils.maybe_parse_reset_bounds
        low_bound = np.array([new_low, new_low, new_low, new_low], dtype=np.float32)
        high_bound = np.array([new_high, new_high, new_high, new_high], dtype=np.float32)
        
        # ç”Ÿæˆéšæœºåˆå§‹çŠ¶æ€
        self.state = self.np_random.uniform(low=low_bound, high=high_bound, size=(4,))
        self.steps_beyond_terminated = None

        if self.render_mode == "human":
            self.render()
            
        # ğŸ” è°ƒè¯•è¾“å‡ºï¼šéªŒè¯ç”Ÿæˆçš„çŠ¶æ€
        x, x_dot, theta, theta_dot = self.state
        print(f"    ğŸ² ç”ŸæˆçŠ¶æ€: x={x:.3f}, Î¸={theta:.3f}, x_dot={x_dot:.3f}, Î¸_dot={theta_dot:.3f}")
        
        return np.array(self.state, dtype=np.float32), {}
    
    return reset

def update_environment_reset_range(new_low, new_high):
    """
    æ›´æ–°ç¯å¢ƒçš„resetèŒƒå›´
    """
    print(f"ğŸš€ å¼€å§‹æ›´æ–°ç¯å¢ƒresetèŒƒå›´: [{new_low}, {new_high}]")
    import myCartpoleF
    import inspect
    # æ£€æŸ¥åŸå§‹resetæ–¹æ³•
    original_reset = myCartpoleF.myCartPoleEnvF.reset
    print(f"ğŸ“‹ åŸå§‹resetæ–¹æ³•: {original_reset}")
    
    # åˆ›å»ºæ–°çš„resetæ–¹æ³•
    new_reset_method = create_dynamic_reset_method(new_low, new_high)
    
    # æ›¿æ¢ç±»æ–¹æ³•
    myCartpoleF.myCartPoleEnvF.reset = new_reset_method
    
    # éªŒè¯æ›¿æ¢æ˜¯å¦æˆåŠŸ
    updated_reset = myCartpoleF.myCartPoleEnvF.reset
    print(f"ğŸ“‹ æ›´æ–°åresetæ–¹æ³•: {updated_reset}")
    return None
    
## current_rangeæ˜¯æ›´æ–°å¥½çš„åˆå§‹èŒƒå›´ï¼Œè¿™ä¸ªä¼šåœ¨ä¸»æ–¹æ³•è°ƒç”¨çš„æ—¶å€™ä¿®æ”¹å¤„ç†
def run_100_tests_with_dynamic_reset(Test_Path, current_range):
    """
    ä¿®å¤ç‰ˆæœ¬ï¼šæ­£ç¡®çš„æ¨¡å—é‡è½½å’Œresetæ–¹æ³•æ›´æ–°é¡ºåº
    """
    print(f"\nğŸš€ å¼€å§‹10000æ¬¡æµ‹è¯•: Â±{current_range}")
    print("="*60)
    
    # ğŸ”§ å…ˆé‡è½½æ¨¡å—ï¼ˆæ¸…ç†ä¹‹å‰çš„ä¿®æ”¹ï¼‰
    import importlib
    import myCartpoleF
    importlib.reload(myCartpoleF)
    
    # ğŸ”§ é‡æ–°åº”ç”¨resetæ–¹æ³•ä¿®æ”¹
    print("ğŸ”§ é‡æ–°åº”ç”¨resetæ–¹æ³•...")
    update_success = update_environment_reset_range(-current_range, current_range)
    
    # ğŸ“ æ³¨å†Œæ–°ç¯å¢ƒ
    dynamic_env_name = f'CartPoleLab_Dynamic_{current_range:.3f}'.replace('.', '_')
    
    try:
        gym.register(
            id=dynamic_env_name,
            entry_point='myCartpoleF:myCartPoleEnvF',
            reward_threshold=balance_time / h_in * 0.95,
            max_episode_steps=int(balance_time / h_in)
        )
        print(f"âœ… ç¯å¢ƒæ³¨å†ŒæˆåŠŸ: {dynamic_env_name}")
    except Exception as e:
        print(f"âŒ ç¯å¢ƒæ³¨å†Œå¤±è´¥: {e}")
        return None
    
    # ğŸ® åˆ›å»ºç¯å¢ƒ
    print("ğŸ® åˆ›å»ºç¯å¢ƒ...")
    env = gym.make(dynamic_env_name, render_mode=None)
    env = DummyVecEnv([lambda: env])
    model = PPO.load(Test_Path, env=env)
    
    # ğŸ“Š åˆå§‹åŒ–ç»Ÿè®¡
    all_episodes_data = []
    total_test_stats = {
        'total_episodes': 0,
        'successful_episodes': 0,
        'average_steps': 0,
        'average_balance_rate': 0,
        'perfect_episodes': 0,
        'excellent_episodes': 0,
        'good_episodes': 0,
        'failed_episodes': 0
    }
    
    print("ğŸ® å¼€å§‹10000æ¬¡episodeæµ‹è¯•...")
    
    ## æ˜¯å¦å­˜åœ¨å¤±è´¥æƒ…å†µ
    is_false_or = True
    
    ## è¿™é‡Œé¢å¡«å……æµ‹è¯•ä»£ç 
    for i in range(10000):
        obs = env.reset()
        
        # ğŸ”§ è§£æåˆå§‹è§‚æµ‹å€¼
        if obs.ndim == 2:
            initial_state = obs[0]
        else:
            initial_state = obs
        
        x, x_dot, theta, theta_dot = initial_state
        print(f"Episode {i+1:3d}: åˆå§‹çŠ¶æ€ x={x:.3f}, Î¸={theta:.3f}, x_dot={x_dot:.3f}, Î¸_dot={theta_dot:.3f}")
        
        # ğŸ“Š å•ä¸ªepisodeçš„ç»Ÿè®¡æ•°æ®
        episode_stats = {
            'episode_id': i + 1,
            'initial_state': initial_state.copy(),
            'total_steps': 0,
            'perfect_steps': 0,
            'excellent_steps': 0,
            'good_steps': 0,
            'basic_steps': 0,
            'struggling_steps': 0,
            'lost_steps': 0,
            'final_status': '',
            'episode_duration': 0,
            'success': False
        }

        start_time = time.time()
        step_count = 0
        done = False
        
        # ğŸ® è¿è¡Œå•ä¸ªepisode
        while not done and step_count < 2000:  # æœ€å¤§2000æ­¥
            # æ¨¡å‹é¢„æµ‹åŠ¨ä½œ
            action, _states = model.predict(obs, deterministic=True)
            obs, reward, done, info = env.step(action)
            step_count += 1
            
            # è§£æå½“å‰çŠ¶æ€
            if obs.ndim == 2:
                current_state = obs[0]
            else:
                current_state = obs
                
            x, x_dot, theta, theta_dot = current_state
            
            # ğŸ¯ è¯„ä¼°å½“å‰å¹³è¡¡çŠ¶æ€
            balance_quality, balance_status, is_balanced = check_balance_status_fixed(x, theta, x_dot, theta_dot)
            
            # ğŸ“ˆ æ›´æ–°ç»Ÿè®¡
            episode_stats['total_steps'] += 1
            if balance_quality >= 95:
                episode_stats['perfect_steps'] += 1
            elif balance_quality >= 80:
                episode_stats['excellent_steps'] += 1
            elif balance_quality >= 60:
                episode_stats['good_steps'] += 1
            elif balance_quality >= 40:
                episode_stats['basic_steps'] += 1
            elif balance_quality >= 20:
                episode_stats['struggling_steps'] += 1
            else:
                episode_stats['lost_steps'] += 1
        
        # ğŸ“Š è®¡ç®—episodeç»“æœ
        episode_stats['episode_duration'] = time.time() - start_time
        episode_stats['final_status'] = balance_status
        
        # è®¡ç®—è¯¥episodeçš„å¹³è¡¡ç‡
        balanced_steps = (episode_stats['perfect_steps'] + 
                        episode_stats['excellent_steps'] + 
                        episode_stats['good_steps'] + 
                        episode_stats['basic_steps'])
        
        episode_balance_rate = (balanced_steps / episode_stats['total_steps']) * 100 if episode_stats['total_steps'] > 0 else 0
        episode_stats['balance_rate'] = episode_balance_rate
        
        # ğŸ¯ åˆ¤æ–­episodeæˆåŠŸä¸å¦
        if episode_balance_rate >= 40 and episode_stats['total_steps'] >= 1000:
            episode_stats['success'] = True
            total_test_stats['successful_episodes'] += 1
            
            # ç»†åˆ†æˆåŠŸç­‰çº§
            if episode_balance_rate >= 90:
                total_test_stats['perfect_episodes'] += 1
            elif episode_balance_rate >= 80:
                total_test_stats['excellent_episodes'] += 1
            else:
                total_test_stats['good_episodes'] += 1
        else:
            episode_stats['success'] = False
            is_false_or = False
            total_test_stats['failed_episodes'] += 1
        
        # ğŸ’¾ ä¿å­˜episodeæ•°æ®
        all_episodes_data.append(episode_stats)
        
        # ğŸ–¥ï¸ å®æ—¶è¾“å‡ºè¿›åº¦
        status_icon = "âœ…" if episode_stats['success'] else "âŒ"
        print(f"  {status_icon} æ­¥æ•°:{step_count:4d} | å¹³è¡¡ç‡:{episode_balance_rate:5.1f}% | çŠ¶æ€:{balance_status}")
        
        # æ¯10ä¸ªepisodeè¾“å‡ºä¸€æ¬¡æ±‡æ€»
        if (i + 1) % 10 == 0:
            current_success_rate = (total_test_stats['successful_episodes'] / (i + 1)) * 100
            print(f"\nğŸ“Š è¿›åº¦: {i+1}/100 | å½“å‰æˆåŠŸç‡: {current_success_rate:.1f}%")
            print("-" * 40)

    env.close()

    # ğŸ”„ è¿”å›ç»“æœç»™ä¸»å¾ªç¯ä½¿ç”¨
    return {
        'average_balance_rate': total_test_stats['average_balance_rate'],
        'average_steps': total_test_stats['average_steps'],
        'if_fail': is_false_or,
        'all_episodes_data': all_episodes_data,
        'total_stats': total_test_stats
    }

# ä¸»å¾ªç¯ï¼šåŠ¨æ€ä¿®æ”¹resetä»¥åŠæ¯æ¬¡å¾ªç¯çš„100æ¬¡æµ‹è¯•
def dynamic_reset_loop(Test_path):
    """
    ä¸»å¾ªç¯ï¼šåŠ¨æ€ä¿®æ”¹resetèŒƒå›´å¹¶è¿›è¡Œæµ‹è¯•
    """
    print("å¼€å§‹åŠ¨æ€resetèŒƒå›´æµ‹è¯•å¾ªç¯")
    
    # å‚æ•°è®¾ç½®
    # éªŒè¯ä¸€ä¸‹æ˜¯å¦æˆåŠŸä¿®æ”¹äº†resetæ¡ä»¶
    initial_range = 0.08
    range_step = 0.02
    max_range = 0.20
    current_range = initial_range
    
    ## è¿™ä¸€éƒ¨åˆ†æ˜¯è½¬æ¢èŒƒå›´çš„å¾ªç¯èŒƒå›´ï¼ˆè¿™é‡Œåº”è¯¥è¿˜éœ€è¦ä¿®æ”¹ä¸€ä¸‹ï¼‰
    while current_range <= max_range:
        print(f"\n{'='*60}")
        print(f"å½“å‰æµ‹è¯•èŒƒå›´: Â±{current_range}")
        print(f"{'='*60}")
        # åŠ¨æ€æ›´æ–°resetèŒƒå›´
        update_environment_reset_range(-current_range, current_range)
        # è¿è¡Œ100æ¬¡æµ‹è¯•
        result = run_100_tests_with_dynamic_reset(Test_path, current_range)
        # æ·»åŠ resultçš„åˆ†æé€»è¾‘ï¼Œçœ‹çœ‹æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼›å¦‚æœç»“æœä¸ç¨³å®šï¼Œåˆ™é€€å‡ºå¾ªç¯ï¼Œä¿ç•™current range
        if result['if_fail'] == False:
            print(f"\nğŸš¨ æ£€æµ‹åˆ°é—®é¢˜ï¼")
            print(f"   å»ºè®®çš„ç¨³å®šè®­ç»ƒèŒƒå›´: Â±{current_range:.3f}")
            break
        else:
            print(f"\nâœ… èŒƒå›´ Â±{current_range} æµ‹è¯•é€šè¿‡")
            print(f" ç»§ç»­æµ‹è¯•æ›´å¤§èŒƒå›´...")
        # æ‰©å¤§èŒƒå›´ï¼ˆè¿™é‡Œåº”è¯¥è¿˜éœ€è¦ä¿®æ”¹ä¸€ä¸‹ï¼‰
        current_range = round(current_range + range_step, 3) 
    return None

# æ‰§è¡ŒåŠ¨æ€resetå¾ªç¯
Best_Path = os.path.join('Training', 'Saved Models', 'best_model')
results = dynamic_reset_loop(Best_Path)